{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"baselineT5.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VqPHSHm_h5Si","executionInfo":{"status":"ok","timestamp":1638696237821,"user_tz":300,"elapsed":55390,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}},"outputId":"a2c836e7-d3ab-4414-83d5-fbdcc7a8bbdd"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QEHJc1wPj2JE","executionInfo":{"status":"ok","timestamp":1638696239147,"user_tz":300,"elapsed":1329,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}},"outputId":"0dea4802-7cba-40f5-83ba-b7180285eeeb"},"source":["%cd gdrive/MyDrive/Colab\\ Notebooks/4650Project/"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Colab Notebooks/4650Project\n"]}]},{"cell_type":"markdown","metadata":{"id":"5mnde4lldXt5"},"source":["Loading Data"]},{"cell_type":"code","metadata":{"id":"I8cI8xfRXwex","colab":{"base_uri":"https://localhost:8080/","height":218},"executionInfo":{"status":"error","timestamp":1638696240382,"user_tz":300,"elapsed":1237,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}},"outputId":"fc148312-d22c-4897-d511-0452fbb4abed"},"source":["sae = open(\"data/sae_samples.tsv\").read().replace('\\t', '')\n","sae = sae.split('\\n')\n","sae = sae[0:-1]\n","print(len(sae))"],"execution_count":3,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-f652a5bcd4a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/sae_samples.tsv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msae\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/sae_samples.tsv'"]}]},{"cell_type":"code","metadata":{"id":"0gLTkEvRYYjG","executionInfo":{"status":"aborted","timestamp":1638696240374,"user_tz":300,"elapsed":620,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["sae[-2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DM6LwYRDYUt-","executionInfo":{"status":"aborted","timestamp":1638696240375,"user_tz":300,"elapsed":621,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["aave = open(\"data/aave_samples.tsv\").read().replace('\\t', '')\n","aave = aave.split('\\n')\n","print(len(aave))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IZJ_yVW6Ymtt","executionInfo":{"status":"aborted","timestamp":1638696240376,"user_tz":300,"elapsed":621,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["aave[-2]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hZoBIYvCdZ_N"},"source":["Re-arrangement & Train-Test-Val Split"]},{"cell_type":"code","metadata":{"id":"jedlyyIxabBl","executionInfo":{"status":"aborted","timestamp":1638696240376,"user_tz":300,"elapsed":621,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["data = {}\n","data['sae'] = sae\n","data['aave'] = aave"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_NijfPukfRv","executionInfo":{"status":"aborted","timestamp":1638696240376,"user_tz":300,"elapsed":621,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UHQyK1Qakiy8","executionInfo":{"status":"aborted","timestamp":1638696240376,"user_tz":300,"elapsed":621,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["data = pd.DataFrame(data)\n","data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FWuMQvXRleG2","executionInfo":{"status":"aborted","timestamp":1638696240377,"user_tz":300,"elapsed":622,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["data[0:1615].to_csv(\"data/training/train.csv\", index=False)\n","data[1615:1817].to_csv(\"data/training/val.csv\", index=False)\n","data[1817:].to_csv(\"data/training/test.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RKnhD8nRiVL5"},"source":["#Training start here: "]},{"cell_type":"code","metadata":{"id":"3rCUbZgAOvd5","executionInfo":{"status":"aborted","timestamp":1638696240377,"user_tz":300,"elapsed":622,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["!pip install sentencepiece==0.1.91"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s_2RZo44i053","executionInfo":{"status":"aborted","timestamp":1638696240377,"user_tz":300,"elapsed":622,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3G1g5M2OiwgY","executionInfo":{"status":"aborted","timestamp":1638696240377,"user_tz":300,"elapsed":622,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["import torch\n","import transformers\n","import pandas as pd\n","from pprint import pprint\n","from tqdm.notebook import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zgk_ShInl2CT","executionInfo":{"status":"aborted","timestamp":1638696240378,"user_tz":300,"elapsed":623,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["train = pd.read_csv(\"data/training/train.csv\")\n","train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YfYq7HfNomDq","executionInfo":{"status":"aborted","timestamp":1638696240378,"user_tz":300,"elapsed":623,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["val = pd.read_csv(\"data/training/val.csv\")\n","val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yZuo7KikfsI1","executionInfo":{"status":"aborted","timestamp":1638696240379,"user_tz":300,"elapsed":13,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels, length):\n","        self.encodings = encodings\n","        self.labels = labels\n","        self.length = length\n","\n","    def __getitem__(self, idx):\n","        encoding_item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        label_item = {key: torch.tensor(val[idx]) for key, val in self.labels.items()}\n","        return encoding_item, label_item\n","\n","    def __len__(self):\n","        return self.length\n","\n","def get_dataset(train, val):\n","    '''\n","    train: list of [sae, aave] for training \n","    val: list of [sae, aave] for validation\n","    '''\n","    #from transformers import BartTokenizerFast\n","    from transformers import T5Tokenizer\n","\n","    #tokenizer = BartTokenizerFast.from_pretrained('facebook/bart-base')\n","    tokenizer = T5Tokenizer.from_pretrained('t5-base')\n","\n","    train_sae = tokenizer(list(train['sae']), padding=True)\n","    train_aave = tokenizer(list(train['aave']), padding=True)\n","    val_sae = tokenizer(list(val['sae']), padding=True)\n","    val_aave = tokenizer(list(val['aave']), padding=True)\n","\n","    train_dataset = Dataset(train_sae, train_aave, length = len(list(train['sae'])))\n","    val_dataset = Dataset(val_sae, val_aave, length=len(list(val['sae'])))\n","\n","    return train_dataset, val_dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nd1spHs1OOdQ","executionInfo":{"status":"aborted","timestamp":1638696240379,"user_tz":300,"elapsed":12,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["from transformers import T5Tokenizer\n","tokenizer = T5Tokenizer.from_pretrained('t5-base')\n","print(tokenizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BcvOaceKodA4","executionInfo":{"status":"aborted","timestamp":1638696240379,"user_tz":300,"elapsed":12,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["train_dataset, val_dataset = get_dataset(train, val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKMMI7XDqhiq","executionInfo":{"status":"aborted","timestamp":1638696240379,"user_tz":300,"elapsed":12,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["print(len(train_dataset))\n","print(type(train_dataset))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Ruu9c7lqk53","executionInfo":{"status":"aborted","timestamp":1638696240379,"user_tz":300,"elapsed":12,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["import torch\n","from torch.nn import BCEWithLogitsLoss, BCELoss\n","\n","from torch.utils.data import DataLoader\n","\n","#from transformers import BartForConditionalGeneration, AdamW\n","from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(torch.cuda.is_available())\n","print(device)\n","\n","#model =  BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n","model = T5ForConditionalGeneration.from_pretrained('t5-base')\n","\n","model.to(device)\n","model.train()\n","\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=False)\n","\n","optim = AdamW(model.parameters(), lr=5e-5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Xp0GErYrTmy","executionInfo":{"status":"aborted","timestamp":1638696240380,"user_tz":300,"elapsed":13,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["WEIGHT_PATH = 'weights/T5'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sBN31LbyrXJc","executionInfo":{"status":"aborted","timestamp":1638696240380,"user_tz":300,"elapsed":12,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["def train(epochs=10):\n","    train_loss_set = list()\n","    for epoch in tqdm(range(epochs)):\n","        for batch in train_loader:\n","            input, label = batch\n","            #print(input)\n","\n","            optim.zero_grad()\n","\n","            input_ids = input['input_ids'].to(device)\n","            attention_mask = input['attention_mask'].to(device)\n","\n","            labels = label['input_ids'].to(device)\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","            loss = outputs[0]\n","            train_loss_set.append(loss.item())\n","\n","            # Backward pass\n","            loss.backward()\n","\n","            optim.step()\n","\n","        print(\"Finished epoch {}\".format(epoch))\n","\n","    model.save_pretrained(WEIGHT_PATH)\n","    return train_loss_set"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6NxcBDaErvnU","executionInfo":{"status":"aborted","timestamp":1638696240380,"user_tz":300,"elapsed":12,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["loss_values = train(10)\n","\n","import matplotlib.pyplot as plt\n","\n","plt.plot(loss_values)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"durQNXNjsz6v","executionInfo":{"status":"aborted","timestamp":1638696240380,"user_tz":300,"elapsed":12,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["WEIGHT_PATH = 'weights/T5'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lpS9NPoHtR_R","executionInfo":{"status":"aborted","timestamp":1638696240381,"user_tz":300,"elapsed":13,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["DATAPATH = 'data/training/test.csv'\n","import torch\n","\n","# from transformers import BartTokenizerFast\n","# tokenizer = BartTokenizerFast.from_pretrained('facebook/bart-base')\n","\n","from transformers import T5Tokenizer\n","tokenizer = T5Tokenizer.from_pretrained('t5-base')\n","\n","def get_data(path=DATAPATH):\n","\n","  test = pd.read_csv(\"data/training/test.csv\")\n","  # print(test)\n","  sae_list = list(test['sae'])\n","  aave_list = list(test['aave'])\n","  return sae_list, aave_list\n","\n","class TestDataset(torch.utils.data.Dataset):\n","  def __init__(self, encodings, inputs, labels, length):\n","      self.encodings = encodings\n","      self.inputs = inputs\n","      self.labels = labels\n","      self.length = length\n","\n","  def __getitem__(self, idx):\n","      encoding_item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","      return (encoding_item, self.inputs[idx], self.labels[idx])\n","\n","  def __len__(self):\n","      return self.length\n","\n","def get_dataset(sae_list, aave_list):\n","\n","  sae_encodings = tokenizer(sae_list, padding=True)\n","\n","  test_dataset = TestDataset(encodings = sae_encodings, inputs = sae_list, labels = aave_list, length = len(aave_list))\n","\n","  return test_dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Ik-ZaOHvQRp","executionInfo":{"status":"aborted","timestamp":1638696240381,"user_tz":300,"elapsed":13,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["sae_list, aave_list = get_data(path = 'data/training/test.csv')\n","test_dataset = get_dataset(sae_list, aave_list)\n","# print(test_dataset.inputs)\n","# print(test_dataset.labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6AfRg0YHvhC_","executionInfo":{"status":"aborted","timestamp":1638696240381,"user_tz":300,"elapsed":13,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["from transformers import T5ForConditionalGeneration\n","#from transformers import BartForConditionalGeneration\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","from torch.utils.data import DataLoader\n","from tqdm.notebook import tqdm\n","\n","def validate(val_dataset):\n","    model =  T5ForConditionalGeneration.from_pretrained(WEIGHT_PATH)\n","    #model =  BartForConditionalGeneration.from_pretrained(WEIGHT_PATH)\n","    model.to(device)\n","    model.eval()\n","\n","    val_loader = DataLoader(val_dataset, batch_size=5, shuffle=False)\n","\n","    print(\"Evaluating on {} questions\".format(len(val_dataset)))\n","    \n","    org_inputs = []\n","    generated_texts = []\n","    references = []\n","    for batch in val_loader:\n","            input, org_input, reference = batch\n","            for o in org_input:\n","              org_inputs.append(o)\n","            for r in reference:\n","              references.append(r)\n","\n","            input_ids = input['input_ids'].to(device)\n","            attention_mask = input['attention_mask'].to(device)\n","\n","            with torch.no_grad():\n","                generated_sequences = model.generate(\n","                    input_ids=input_ids,\n","                    attention_mask = attention_mask,\n","                    max_length=600,\n","                    temperature=0.8,\n","                    top_k=5,\n","                    top_p=0.9,\n","                    repetition_penalty=0.8\n","                    )\n","                for sequence in generated_sequences:\n","                    hypothesis = tokenizer.decode(sequence, clean_up_tokenization_spaces=True)\n","                    hypothesis = hypothesis[5:]\n","                    #print(hypothesis)\n","                    end = hypothesis.index('</s>')\n","                    hypothesis = hypothesis[0:end]\n","                    generated_texts.append(hypothesis)\n","    return org_inputs, generated_texts, references"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vSrCX3uHxpvb","executionInfo":{"status":"aborted","timestamp":1638696240381,"user_tz":300,"elapsed":13,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["org_inputs, generated_texts, references = validate(test_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oLO9rYHc0m1X","executionInfo":{"status":"aborted","timestamp":1638696240381,"user_tz":300,"elapsed":13,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["print(len(org_inputs))\n","print(len(generated_texts))\n","print(len(references))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3f9GbJ2T1CTE","executionInfo":{"status":"aborted","timestamp":1638696240382,"user_tz":300,"elapsed":14,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["for i in range(0,10):\n","  print(org_inputs[i])\n","  print(references[i])\n","  print(generated_texts[i])\n","  print('==========================================================================')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xBVe1KnAL02C","executionInfo":{"status":"aborted","timestamp":1638696240382,"user_tz":300,"elapsed":14,"user":{"displayName":"Jason Qi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14258838799704967372"}}},"source":["output = {}\n","output['org_inputs'] = org_inputs\n","output['references'] = references\n","output['generated_texts'] = generated_texts\n","output = pd.DataFrame(output)\n","output.to_csv(\"data/T5_output.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uF081GME51xN"},"source":["import torch\n","import nltk\n","import numpy as np\n","from datasets import load_metric\n","from datetime import datetime\n","\n","def compute_metrics(predictions, labels):\n","\n","    if type(labels) == list:\n","        labels = torch.tensor(labels)\n","\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = torch.where(labels != -100, labels, tokenizer.eos_token_id)\n","\n","    predictions = predictions.cpu()\n","    labels = labels.cpu()\n","\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    joined_preds = list(map(lambda x: ''.join(x).replace('\\n', ''), decoded_preds))\n","    joined_labels = list(map(lambda x: ''.join(x).replace('\\n', ''), decoded_labels))\n","\n","    # Rouge expects a newline after each sentence\n","    nled_preds = list(map(lambda x: \"\\n\".join(nltk.sent_tokenize(x)), joined_preds))\n","    nled_labels = list(map(lambda x: \"\\n\".join(nltk.sent_tokenize(x)), joined_labels))\n","\n","    rouge = load_metric(\"rouge\")\n","    result = rouge.compute(predictions=nled_preds, references=nled_labels, use_stemmer=True)\n","    # Extract a few results\n","    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n","\n","    # Add mean generated length\n","    prediction_lens = [torch.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","\n","    # BERTScore # roberta-large => cuda out of memory\n","    bertscore = load_metric(\"bertscore\")\n","    bs_result = bertscore.compute(predictions=joined_preds, references=joined_labels, lang='en')\n","    result = dict(result, **{'BS ' + k: np.mean(v) for k, v in bs_result.items() if k != 'hashcode'})\n","\n","    # BLEU\n","    bleu = load_metric(\"bleu\")\n","    preds = list(map(lambda x: list(map(lambda y: str(y), x)), joined_preds))\n","    refs = list(map(lambda x: [list(map(lambda y: str(y), x)),], joined_labels))\n","    result['bleu'] = bleu.compute(predictions=preds, references=refs)['bleu']\n","\n","    return {k: v for k, v in result.items()}, joined_preds, joined_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LiJA47lq6Dkm"},"source":["import transformers\n","transformers.logging.set_verbosity_error()\n","\n","from tqdm import tqdm\n","\n","metrics = {}\n","results = {k: [] for k in ['org_inputs', 'references', 'generated_texts']}\n","pred, eval = [], []\n","for i, x in enumerate(tqdm(val_data)):\n","    # if i == 10: break\n","    input_ids = torch.tensor(x['input_ids'][:prompt_lengths[i]]).cuda()\n","    prediction = model.generate(\n","        input_ids.unsqueeze(0),\n","        temperature=0.8,\n","        no_repeat_ngram_size=2,\n","        max_length=TOTAL_LEN,\n","        truncation=False,\n","    )[0]\n","    input_len = len(input_ids)\n","    results['org_inputs'] += [tokenizer.decode(input_ids).replace(\"\\n\", \" \") + \"\\n\",]\n","    \n","    pred += [prediction[input_len:].tolist(),]\n","    eval += [x['labels'][input_len:],]\n","    pred[-1] += [tokenizer.eos_token_id for _ in range(TOTAL_LEN - len(pred[-1]))]\n","    eval[-1] += [-100 for _ in range(TOTAL_LEN - len(eval[-1]))]\n","\n","pred = torch.tensor(pred)\n","eval = torch.tensor(eval)\n","\n","d, results['generated_texts'], results['references'] = compute_metrics(pred, eval)\n","for (k, v) in d.items():\n","    if k not in metrics.keys(): metrics[k] = []\n","    metrics[k] += [v,]"],"execution_count":null,"outputs":[]}]}